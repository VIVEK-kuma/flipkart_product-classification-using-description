{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flipkart Product category Classification from description",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWwt7NwJIHyp"
      },
      "source": [
        "**NLP**: Product category prediction using product description\n",
        "                                      "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlmZoSyKJT9J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d4002f-9601-490d-dcf8-b73a02c1b7db"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-YapdgUcPbo"
      },
      "source": [
        "#library for dataframe and its operations\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "nHL9hc5_fnwK",
        "outputId": "232fc7d7-f413-4151-ce47-3dddbdba1655"
      },
      "source": [
        "#data reading just upload data to session storage and use it\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/flipkart_NLP_classification/flipkart_com-ecommerce_sample - flipkart_com-ecommerce_sample.csv\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>uniq_id</th>\n",
              "      <th>crawl_timestamp</th>\n",
              "      <th>product_url</th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_category_tree</th>\n",
              "      <th>pid</th>\n",
              "      <th>retail_price</th>\n",
              "      <th>discounted_price</th>\n",
              "      <th>image</th>\n",
              "      <th>is_FK_Advantage_product</th>\n",
              "      <th>description</th>\n",
              "      <th>product_rating</th>\n",
              "      <th>overall_rating</th>\n",
              "      <th>brand</th>\n",
              "      <th>product_specifications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c2d766ca982eca8304150849735ffef9</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/alisha-solid-women-s-c...</td>\n",
              "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
              "      <td>[\"Clothing &gt;&gt; Women's Clothing &gt;&gt; Lingerie, Sl...</td>\n",
              "      <td>SRTEH2FF9KEDEFGF</td>\n",
              "      <td>999.0</td>\n",
              "      <td>379.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/short/u/4/a/...</td>\n",
              "      <td>0</td>\n",
              "      <td>Key Features of Alisha Solid Women's Cycling S...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Alisha</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Number of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7f7036a6d550aaa89d34c77bd39a5e48</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/fabhomedecor-fabric-do...</td>\n",
              "      <td>FabHomeDecor Fabric Double Sofa Bed</td>\n",
              "      <td>[\"Furniture &gt;&gt; Living Room Furniture &gt;&gt; Sofa B...</td>\n",
              "      <td>SBEEH3QGU7MFYJFY</td>\n",
              "      <td>32157.0</td>\n",
              "      <td>22646.0</td>\n",
              "      <td>[\"http://img6a.flixcart.com/image/sofa-bed/j/f...</td>\n",
              "      <td>0</td>\n",
              "      <td>FabHomeDecor Fabric Double Sofa Bed (Finish Co...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>FabHomeDecor</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Installati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f449ec65dcbc041b6ae5e6a32717d01b</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/aw-bellies/p/itmeh4grg...</td>\n",
              "      <td>AW Bellies</td>\n",
              "      <td>[\"Footwear &gt;&gt; Women's Footwear &gt;&gt; Ballerinas &gt;...</td>\n",
              "      <td>SHOEH4GRSUBJGZXE</td>\n",
              "      <td>999.0</td>\n",
              "      <td>499.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/shoe/7/z/z/r...</td>\n",
              "      <td>0</td>\n",
              "      <td>Key Features of AW Bellies Sandals Wedges Heel...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>AW</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Ideal For\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0973b37acd0c664e3de26e97e5571454</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/alisha-solid-women-s-c...</td>\n",
              "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
              "      <td>[\"Clothing &gt;&gt; Women's Clothing &gt;&gt; Lingerie, Sl...</td>\n",
              "      <td>SRTEH2F6HUZMQ6SJ</td>\n",
              "      <td>699.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/short/6/2/h/...</td>\n",
              "      <td>0</td>\n",
              "      <td>Key Features of Alisha Solid Women's Cycling S...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Alisha</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Number of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bc940ea42ee6bef5ac7cea3fb5cfbee7</td>\n",
              "      <td>2016-03-25 22:59:23 +0000</td>\n",
              "      <td>http://www.flipkart.com/sicons-all-purpose-arn...</td>\n",
              "      <td>Sicons All Purpose Arnica Dog Shampoo</td>\n",
              "      <td>[\"Pet Supplies &gt;&gt; Grooming &gt;&gt; Skin &amp; Coat Care...</td>\n",
              "      <td>PSOEH3ZYDMSYARJ5</td>\n",
              "      <td>220.0</td>\n",
              "      <td>210.0</td>\n",
              "      <td>[\"http://img5a.flixcart.com/image/pet-shampoo/...</td>\n",
              "      <td>0</td>\n",
              "      <td>Specifications of Sicons All Purpose Arnica Do...</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>No rating available</td>\n",
              "      <td>Sicons</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Pet Type\",...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            uniq_id  ...                             product_specifications\n",
              "0  c2d766ca982eca8304150849735ffef9  ...  {\"product_specification\"=>[{\"key\"=>\"Number of ...\n",
              "1  7f7036a6d550aaa89d34c77bd39a5e48  ...  {\"product_specification\"=>[{\"key\"=>\"Installati...\n",
              "2  f449ec65dcbc041b6ae5e6a32717d01b  ...  {\"product_specification\"=>[{\"key\"=>\"Ideal For\"...\n",
              "3  0973b37acd0c664e3de26e97e5571454  ...  {\"product_specification\"=>[{\"key\"=>\"Number of ...\n",
              "4  bc940ea42ee6bef5ac7cea3fb5cfbee7  ...  {\"product_specification\"=>[{\"key\"=>\"Pet Type\",...\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUk7jW4XckYb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPoBQJx4fZ9q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkm-VMoccq2h",
        "outputId": "e8861656-2e38-4efb-b4bf-7548f99f4ddc"
      },
      "source": [
        "print(df.columns)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['uniq_id', 'crawl_timestamp', 'product_url', 'product_name',\n",
            "       'product_category_tree', 'pid', 'retail_price', 'discounted_price',\n",
            "       'image', 'is_FK_Advantage_product', 'description', 'product_rating',\n",
            "       'overall_rating', 'brand', 'product_specifications'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITzWfltkg9bn"
      },
      "source": [
        "#drop the unnecesarry columns\n",
        "df.drop(['uniq_id', 'crawl_timestamp', 'product_url','pid', 'retail_price', 'discounted_price','image', 'is_FK_Advantage_product','product_rating',\n",
        "       'overall_rating', ], axis=1,inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y3m_mihc1DM",
        "outputId": "ff1ca2f5-8f97-43e4-aca7-ffb938829e7c"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['product_name', 'product_category_tree', 'description', 'brand',\n",
              "       'product_specifications'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "C8C5v32rhEO5",
        "outputId": "9e1cfe0b-1018-4838-feb9-2bc0a45ea0b1"
      },
      "source": [
        "#check for NULL values\n",
        "df[df['description'].isnull()==True]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_category_tree</th>\n",
              "      <th>description</th>\n",
              "      <th>brand</th>\n",
              "      <th>product_specifications</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>Ozel Studio Casual Sleeveless Printed Women's Top</td>\n",
              "      <td>[\"Clothing &gt;&gt; Women's Clothing &gt;&gt; Western Wear...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Ideal For\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17299</th>\n",
              "      <td>Amore Abstract Cushions Cover</td>\n",
              "      <td>[\"Home Furnishing &gt;&gt; Cushions, Pillows &amp; Cover...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Amore</td>\n",
              "      <td>{\"product_specification\"=&gt;[{\"key\"=&gt;\"Brand\", \"v...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            product_name  ...                             product_specifications\n",
              "553    Ozel Studio Casual Sleeveless Printed Women's Top  ...  {\"product_specification\"=>[{\"key\"=>\"Ideal For\"...\n",
              "17299                      Amore Abstract Cushions Cover  ...  {\"product_specification\"=>[{\"key\"=>\"Brand\", \"v...\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3CsrprfdK1W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhJc7Wg-hR-s"
      },
      "source": [
        "#we can drop these two rows so that null values will be avoided and also it will not create much diffrence in our model\n",
        "df.drop(labels=[553,17299],axis=0,inplace =True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka5Xew98dlRM",
        "outputId": "2ba63afc-2fc9-45d2-e336-9b6413621fde"
      },
      "source": [
        "#text cleaning libraries\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m08Pk4FzOnUD"
      },
      "source": [
        "**Text preprocessing**:In this block we are preprocessing text\n",
        "1. First we imported porterstemmer module which is used for stemming text data.\n",
        "2. I have done preprocessing mainly on 2 columns 'product_category_tree' and 'description'.\n",
        "3. I have ignored the deleted rows(553 and 17299)\n",
        "4. first in 'product_category_tree' I removed all the elements except alphabets and spaces then i convert it all in lowercase elements and then split it and join using space and appended in the list corpus.\n",
        "5. Secondly in 'description' column I removed all the elements except alphabets and spaces then i convert it all in lowercase elements after that I have deleted all the stopwords present in the description and done the stemming using porterstemmer module then split it and join it using space and appended in the list crpus\n",
        "6. This is the basic operation for any NLP project\n",
        "7. I have used set during stemming to improve runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo7obrSFfVYf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P7lrisOia2j"
      },
      "source": [
        "crpus=[]\n",
        "ps=PorterStemmer()\n",
        "corpus=[]\n",
        "for i in range(0,20000):\n",
        " if i!=553 and i!=17299:#because we have removed these two rows\n",
        "  review=re.sub('[^a-zA-Z]',' ',df['product_category_tree'][i])\n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "#we use set here with stopwords to reduce execution time\n",
        "  review=' '.join(review)\n",
        "  corpus.append(review)\n",
        "#description preprocessing\n",
        "  review=re.sub('[^a-zA-Z]',' ',df['description'][i])\n",
        "  \n",
        "  review=review.lower()\n",
        "  review=review.split()\n",
        "  review=[ps.stem(word )for word in review if not word in set(stopwords.words('english'))]\n",
        "  review=' '.join(review)\n",
        "  crpus.append(review)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ipsF6QP5ifmL",
        "outputId": "72a290cc-8315-4550-86a4-c58a36312029"
      },
      "source": [
        "#declaring and showing dataframe containing only these two coumns \n",
        "df=pd.DataFrame({\"product_category\":corpus,\"description\":crpus})\n",
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_category</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clothing women s clothing lingerie sleep swimw...</td>\n",
              "      <td>key featur alisha solid women cycl short cotto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>furniture living room furniture sofa beds futo...</td>\n",
              "      <td>fabhomedecor fabric doubl sofa bed finish colo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>footwear women s footwear ballerinas aw bellies</td>\n",
              "      <td>key featur aw belli sandal wedg heel casual aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clothing women s clothing lingerie sleep swimw...</td>\n",
              "      <td>key featur alisha solid women cycl short cotto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pet supplies grooming skin coat care shampoo s...</td>\n",
              "      <td>specif sicon purpos arnica dog shampoo ml gene...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    product_category                                        description\n",
              "0  clothing women s clothing lingerie sleep swimw...  key featur alisha solid women cycl short cotto...\n",
              "1  furniture living room furniture sofa beds futo...  fabhomedecor fabric doubl sofa bed finish colo...\n",
              "2    footwear women s footwear ballerinas aw bellies  key featur aw belli sandal wedg heel casual aw...\n",
              "3  clothing women s clothing lingerie sleep swimw...  key featur alisha solid women cycl short cotto...\n",
              "4  pet supplies grooming skin coat care shampoo s...  specif sicon purpos arnica dog shampoo ml gene..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXGgu7A-ijWc"
      },
      "source": [
        "#first word is depicting the product category so we can drop other words in the product category or we can go for sub-category as required\n",
        "df['product_category'] = df['product_category'].apply(lambda x : x.split()[0][0:].strip())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "v7EnFgdThH5c",
        "outputId": "e55baa6d-4419-481a-ee4b-e1ae2952e292"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_category</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>clothing</td>\n",
              "      <td>key featur alisha solid women cycl short cotto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>furniture</td>\n",
              "      <td>fabhomedecor fabric doubl sofa bed finish colo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>footwear</td>\n",
              "      <td>key featur aw belli sandal wedg heel casual aw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>clothing</td>\n",
              "      <td>key featur alisha solid women cycl short cotto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pet</td>\n",
              "      <td>specif sicon purpos arnica dog shampoo ml gene...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  product_category                                        description\n",
              "0         clothing  key featur alisha solid women cycl short cotto...\n",
              "1        furniture  fabhomedecor fabric doubl sofa bed finish colo...\n",
              "2         footwear  key featur aw belli sandal wedg heel casual aw...\n",
              "3         clothing  key featur alisha solid women cycl short cotto...\n",
              "4              pet  specif sicon purpos arnica dog shampoo ml gene..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPtahZo-RrNh"
      },
      "source": [
        "**Data Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8-x6se_hzLR"
      },
      "source": [
        "#library for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "wRfHgxWXDYVd",
        "outputId": "28b6e5fb-8db3-4bf0-ccd7-b4dce6987bf7"
      },
      "source": [
        "#this is distplot of df.groupby(['description']).size(), i used it as it is a combination of rugplot and kdeplot\n",
        "plt.figure(figsize=(30,70))\n",
        "sns.displot( df.groupby(['description']).size(),kde=False,color='r')\n",
        "plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x5040 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "wmgtTqmbGshG",
        "outputId": "57f50171-0883-492c-b141-bf231aa75a60"
      },
      "source": [
        "#this is distplot of df.groupby([''product_category'']).size(), i used it as it is a combination of rugplot and kdeplot\n",
        "plt.figure(figsize=(30,70))\n",
        "sns.displot( df.groupby(['product_category']).size(),kde=False)\n",
        "plt.show()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x5040 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es4IljSUibPE"
      },
      "source": [
        "#data preprocessing libraries  \n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKaYFBcTiyYa"
      },
      "source": [
        "X=df['description']\n",
        "y=df['product_category']\n",
        "cv= CountVectorizer()\n",
        "X=cv.fit_transform(X)\n",
        "le=LabelEncoder()\n",
        "le=le.fit(y)\n",
        "y=le.transform(y)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n3xWL-xio9y"
      },
      "source": [
        "#library for importing models\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_A65XW9jO8c"
      },
      "source": [
        "#libraries to determine model validity\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syTHHXDaiVli"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_jGCpKWi7WB"
      },
      "source": [
        "**Multinomial Naive bayes Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYH2KyO4jDXo"
      },
      "source": [
        "mnb=MultinomialNB()\n",
        "#model fitting\n",
        "mnb.fit(X_train,y_train)\n",
        "#prediction\n",
        "pred_y=mnb.predict(X_test)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUEyXpYajfp7",
        "outputId": "522e72f4-8e4a-49e9-be16-375aa7284ed3"
      },
      "source": [
        "#check accuracy and underfitting using classification report and accuracy score\n",
        "r=accuracy_score(y_test,pre)\n",
        "print(r)\n",
        "print(classification_report(y_test,pred_y))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9144\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         2\n",
            "           9       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         1\n",
            "          16       0.92      0.99      0.95       239\n",
            "          18       0.81      0.61      0.70       116\n",
            "          19       0.84      0.62      0.72        87\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.86      0.96      0.91       184\n",
            "          26       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       1.00      0.18      0.31        22\n",
            "          35       0.00      0.00      0.00         1\n",
            "          37       0.96      0.99      0.97      1538\n",
            "          38       0.00      0.00      0.00         6\n",
            "          40       0.87      0.81      0.84       146\n",
            "          41       0.00      0.00      0.00         1\n",
            "          44       0.00      0.00      0.00         2\n",
            "          47       0.00      0.00      0.00         1\n",
            "          48       0.00      0.00      0.00         1\n",
            "          49       0.00      0.00      0.00         3\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         2\n",
            "          52       1.00      0.50      0.67         2\n",
            "          55       1.00      1.00      1.00         3\n",
            "          56       0.00      0.00      0.00         1\n",
            "          58       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          64       0.93      0.97      0.95       279\n",
            "          65       0.00      0.00      0.00         2\n",
            "          67       0.93      0.98      0.95        52\n",
            "          69       1.00      0.75      0.86         8\n",
            "          72       0.00      0.00      0.00         1\n",
            "          74       1.00      0.67      0.80         6\n",
            "          76       0.87      0.94      0.90       444\n",
            "          77       1.00      1.00      1.00         1\n",
            "          78       0.00      0.00      0.00         1\n",
            "          80       0.00      0.00      0.00         1\n",
            "          81       0.00      0.00      0.00         1\n",
            "          84       0.88      1.00      0.93       872\n",
            "          93       0.97      0.83      0.90       161\n",
            "          94       0.00      0.00      0.00         1\n",
            "          99       1.00      1.00      1.00         1\n",
            "         101       0.00      0.00      0.00         1\n",
            "         102       0.00      0.00      0.00         1\n",
            "         103       0.00      0.00      0.00         1\n",
            "         104       0.00      0.00      0.00         1\n",
            "         105       0.00      0.00      0.00         1\n",
            "         108       0.00      0.00      0.00         1\n",
            "         110       0.00      0.00      0.00         2\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       0.97      0.92      0.95       280\n",
            "         114       0.00      0.00      0.00         2\n",
            "         118       0.00      0.00      0.00         1\n",
            "         123       0.00      0.00      0.00         4\n",
            "         126       0.91      0.54      0.68        72\n",
            "         127       1.00      0.62      0.77         8\n",
            "         128       0.00      0.00      0.00         1\n",
            "         142       0.00      0.00      0.00         1\n",
            "         143       0.00      0.00      0.00         1\n",
            "         145       0.00      0.00      0.00         1\n",
            "         147       0.00      0.00      0.00         1\n",
            "         151       0.00      0.00      0.00         1\n",
            "         152       0.00      0.00      0.00         1\n",
            "         153       0.00      0.00      0.00         1\n",
            "         154       0.00      0.00      0.00         1\n",
            "         156       0.00      0.00      0.00         2\n",
            "         160       0.00      0.00      0.00         1\n",
            "         161       0.91      0.50      0.65        40\n",
            "         166       0.00      0.00      0.00         1\n",
            "         168       0.78      1.00      0.88        14\n",
            "         170       0.00      0.00      0.00         1\n",
            "         172       0.00      0.00      0.00         1\n",
            "         173       0.00      0.00      0.00         1\n",
            "         175       0.00      0.00      0.00         1\n",
            "         176       0.00      0.00      0.00         1\n",
            "         177       0.92      0.91      0.91       119\n",
            "         178       0.73      0.74      0.74        89\n",
            "         179       0.00      0.00      0.00         1\n",
            "         181       0.00      0.00      0.00         1\n",
            "         183       0.00      0.00      0.00         1\n",
            "         185       0.00      0.00      0.00         1\n",
            "         187       0.00      0.00      0.00         3\n",
            "         188       0.00      0.00      0.00         1\n",
            "         189       0.00      0.00      0.00         1\n",
            "         190       0.95      1.00      0.98       127\n",
            "         191       0.00      0.00      0.00         1\n",
            "         192       0.00      0.00      0.00         1\n",
            "         193       0.00      0.00      0.00         1\n",
            "         194       0.00      0.00      0.00         1\n",
            "         195       0.00      0.00      0.00         1\n",
            "         197       0.00      0.00      0.00         1\n",
            "         198       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.91      5000\n",
            "   macro avg       0.25      0.22      0.23      5000\n",
            "weighted avg       0.90      0.91      0.90      5000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1pr80bBv2bL",
        "outputId": "4cc2bd21-e340-4018-e45e-8eaf16ac910a"
      },
      "source": [
        "print(\"accuracy on test set: \", accuracy_score(y_test,pred_y))\n",
        "print(\"accuracy on training set: \", accuracy_score(y_train,mnb.predict(X_train)))\n",
        "#here accuracy in both the set is comparable so no overfitting condition"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on test set:  0.9144\n",
            "accuracy on training set:  0.934191225496733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqbdwRF9yPFs"
      },
      "source": [
        "**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJykoYaVjm4y",
        "outputId": "3857ef26-fd78-40fa-ec73-e4d3103e886b"
      },
      "source": [
        "lr=LogisticRegression()\n",
        "#Model fitting\n",
        "lr.fit(X_train,y_train)\n",
        "#model prediction\n",
        "pred_y=lr.predict(X_test)\n",
        "#Model performance calcutation and check whether underfitting is there or not.\n",
        "r=accuracy_score(y_test,pred_y)\n",
        "cm=confusion_matrix(y_test,pred_y)\n",
        "print(r)\n",
        "\n",
        "print(classification_report(y_test,pred_y))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9568\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       1.00      1.00      1.00         1\n",
            "           5       1.00      0.50      0.67         2\n",
            "           9       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         1\n",
            "          16       0.98      0.98      0.98       239\n",
            "          18       0.91      0.84      0.88       116\n",
            "          19       0.94      0.98      0.96        87\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.95      0.95      0.95       184\n",
            "          26       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.91      0.95      0.93        22\n",
            "          35       0.00      0.00      0.00         1\n",
            "          37       0.97      0.99      0.98      1538\n",
            "          38       0.40      0.33      0.36         6\n",
            "          40       0.94      0.97      0.95       146\n",
            "          41       0.00      0.00      0.00         1\n",
            "          44       1.00      1.00      1.00         2\n",
            "          47       0.00      0.00      0.00         1\n",
            "          48       0.00      0.00      0.00         1\n",
            "          49       1.00      1.00      1.00         3\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         2\n",
            "          52       1.00      0.50      0.67         2\n",
            "          55       1.00      1.00      1.00         3\n",
            "          56       0.00      0.00      0.00         1\n",
            "          58       1.00      1.00      1.00         2\n",
            "          60       0.50      1.00      0.67         1\n",
            "          61       0.00      0.00      0.00         0\n",
            "          64       0.97      0.99      0.98       279\n",
            "          65       0.00      0.00      0.00         2\n",
            "          67       0.98      0.96      0.97        52\n",
            "          69       1.00      0.88      0.93         8\n",
            "          72       0.00      0.00      0.00         1\n",
            "          74       0.86      1.00      0.92         6\n",
            "          76       0.94      0.95      0.94       444\n",
            "          77       0.00      0.00      0.00         1\n",
            "          78       0.00      0.00      0.00         1\n",
            "          80       1.00      1.00      1.00         1\n",
            "          81       0.00      0.00      0.00         1\n",
            "          84       1.00      0.99      0.99       872\n",
            "          88       0.00      0.00      0.00         0\n",
            "          93       0.92      0.95      0.93       161\n",
            "          94       0.00      0.00      0.00         1\n",
            "          97       0.00      0.00      0.00         0\n",
            "          99       1.00      1.00      1.00         1\n",
            "         101       0.00      0.00      0.00         1\n",
            "         102       1.00      1.00      1.00         1\n",
            "         103       0.00      0.00      0.00         1\n",
            "         104       0.00      0.00      0.00         1\n",
            "         105       1.00      1.00      1.00         1\n",
            "         108       0.00      0.00      0.00         1\n",
            "         110       0.00      0.00      0.00         2\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       0.96      0.97      0.96       280\n",
            "         114       0.00      0.00      0.00         2\n",
            "         118       0.00      0.00      0.00         1\n",
            "         123       0.60      0.75      0.67         4\n",
            "         124       0.00      0.00      0.00         0\n",
            "         126       0.79      0.75      0.77        72\n",
            "         127       1.00      0.88      0.93         8\n",
            "         128       0.00      0.00      0.00         1\n",
            "         142       0.50      1.00      0.67         1\n",
            "         143       0.00      0.00      0.00         1\n",
            "         145       0.00      0.00      0.00         1\n",
            "         147       0.00      0.00      0.00         1\n",
            "         148       0.00      0.00      0.00         0\n",
            "         151       0.00      0.00      0.00         1\n",
            "         152       0.25      1.00      0.40         1\n",
            "         153       0.50      1.00      0.67         1\n",
            "         154       0.00      0.00      0.00         1\n",
            "         156       0.00      0.00      0.00         2\n",
            "         160       1.00      1.00      1.00         1\n",
            "         161       0.95      0.88      0.91        40\n",
            "         166       0.00      0.00      0.00         1\n",
            "         168       0.91      0.71      0.80        14\n",
            "         170       0.00      0.00      0.00         1\n",
            "         172       0.00      0.00      0.00         1\n",
            "         173       1.00      1.00      1.00         1\n",
            "         175       0.00      0.00      0.00         1\n",
            "         176       1.00      1.00      1.00         1\n",
            "         177       0.98      0.94      0.96       119\n",
            "         178       0.82      0.84      0.83        89\n",
            "         179       1.00      1.00      1.00         1\n",
            "         181       0.00      0.00      0.00         1\n",
            "         183       1.00      1.00      1.00         1\n",
            "         185       0.00      0.00      0.00         1\n",
            "         187       1.00      1.00      1.00         3\n",
            "         188       0.00      0.00      0.00         1\n",
            "         189       0.00      0.00      0.00         1\n",
            "         190       0.99      1.00      1.00       127\n",
            "         191       0.00      0.00      0.00         1\n",
            "         192       0.00      0.00      0.00         1\n",
            "         193       0.00      0.00      0.00         1\n",
            "         194       0.00      0.00      0.00         1\n",
            "         195       0.00      0.00      0.00         1\n",
            "         196       0.00      0.00      0.00         0\n",
            "         197       0.00      0.00      0.00         1\n",
            "         198       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.96      5000\n",
            "   macro avg       0.40      0.41      0.39      5000\n",
            "weighted avg       0.95      0.96      0.95      5000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj8hnVXFWrqb"
      },
      "source": [
        "**checking Accuracy**\n",
        "* The Block below is used to calculate accuracy and to check underfitting\n",
        "* the Block below this block is used to check overfitting  by observing difference in model accuracies when prediction is done in test set and training set(if difference is high then there is overfitting and if diffrence is low there is no overfitting)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vohpi8B6kR7T",
        "outputId": "2bf16d03-bd39-4c1b-8b52-05fb0711bee1"
      },
      "source": [
        "#Model gives accuracy of 96 percent which is better than  multinomail naive bayes\n",
        "#check overfitting for multinoial Logistic regression using diffrence in accuracy when model predicts on X_test and X_train\n",
        "print(\"accuracy on test set: \", accuracy_score(y_test,pre))\n",
        "print(\"accuracy on training set: \", accuracy_score(y_train,lr.predict(X_train)))\n",
        "#here difference in accuracy is very less hence model is NOT overfitting \n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on test set:  0.9144\n",
            "accuracy on training set:  0.9970662755034004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPUxSW7wmbMb"
      },
      "source": [
        "## RandomForest algorithms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxQLFIaemapd"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1znXDDUm_fo",
        "outputId": "5498a044-49e5-4ebd-fbc7-132a6454844c"
      },
      "source": [
        "rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "rf.fit(X_train, y_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=2, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTyKjR1mnSpf",
        "outputId": "b4528205-ba22-40f6-a6c2-19dd0383473c"
      },
      "source": [
        "#model prediction\n",
        "pred_y=rf.predict(X_test)\n",
        "#Model performance calcutation and check whether underfitting is there or not.\n",
        "r=accuracy_score(y_test,pred_y)\n",
        "cm=confusion_matrix(y_test,pred_y)\n",
        "print(r)\n",
        "\n",
        "print(classification_report(y_test,pred_y))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.341\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         1\n",
            "           4       0.00      0.00      0.00         1\n",
            "           5       0.00      0.00      0.00         2\n",
            "           9       0.00      0.00      0.00         1\n",
            "          12       0.00      0.00      0.00         1\n",
            "          14       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00       239\n",
            "          18       0.00      0.00      0.00       116\n",
            "          19       0.00      0.00      0.00        87\n",
            "          20       0.00      0.00      0.00         1\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00       184\n",
            "          26       0.00      0.00      0.00         1\n",
            "          29       0.00      0.00      0.00         1\n",
            "          30       0.00      0.00      0.00        22\n",
            "          35       0.00      0.00      0.00         1\n",
            "          37       0.32      1.00      0.48      1538\n",
            "          38       0.00      0.00      0.00         6\n",
            "          40       0.00      0.00      0.00       146\n",
            "          41       0.00      0.00      0.00         1\n",
            "          44       0.00      0.00      0.00         2\n",
            "          47       0.00      0.00      0.00         1\n",
            "          48       0.00      0.00      0.00         1\n",
            "          49       0.00      0.00      0.00         3\n",
            "          50       0.00      0.00      0.00         1\n",
            "          51       0.00      0.00      0.00         2\n",
            "          52       0.00      0.00      0.00         2\n",
            "          55       0.00      0.00      0.00         3\n",
            "          56       0.00      0.00      0.00         1\n",
            "          58       0.00      0.00      0.00         2\n",
            "          60       0.00      0.00      0.00         1\n",
            "          64       0.00      0.00      0.00       279\n",
            "          65       0.00      0.00      0.00         2\n",
            "          67       0.00      0.00      0.00        52\n",
            "          69       0.00      0.00      0.00         8\n",
            "          72       0.00      0.00      0.00         1\n",
            "          74       0.00      0.00      0.00         6\n",
            "          76       0.00      0.00      0.00       444\n",
            "          77       0.00      0.00      0.00         1\n",
            "          78       0.00      0.00      0.00         1\n",
            "          80       0.00      0.00      0.00         1\n",
            "          81       0.00      0.00      0.00         1\n",
            "          84       1.00      0.19      0.32       872\n",
            "          93       0.00      0.00      0.00       161\n",
            "          94       0.00      0.00      0.00         1\n",
            "          99       0.00      0.00      0.00         1\n",
            "         101       0.00      0.00      0.00         1\n",
            "         102       0.00      0.00      0.00         1\n",
            "         103       0.00      0.00      0.00         1\n",
            "         104       0.00      0.00      0.00         1\n",
            "         105       0.00      0.00      0.00         1\n",
            "         108       0.00      0.00      0.00         1\n",
            "         110       0.00      0.00      0.00         2\n",
            "         112       0.00      0.00      0.00         1\n",
            "         113       0.00      0.00      0.00       280\n",
            "         114       0.00      0.00      0.00         2\n",
            "         118       0.00      0.00      0.00         1\n",
            "         123       0.00      0.00      0.00         4\n",
            "         126       0.00      0.00      0.00        72\n",
            "         127       0.00      0.00      0.00         8\n",
            "         128       0.00      0.00      0.00         1\n",
            "         142       0.00      0.00      0.00         1\n",
            "         143       0.00      0.00      0.00         1\n",
            "         145       0.00      0.00      0.00         1\n",
            "         147       0.00      0.00      0.00         1\n",
            "         151       0.00      0.00      0.00         1\n",
            "         152       0.00      0.00      0.00         1\n",
            "         153       0.00      0.00      0.00         1\n",
            "         154       0.00      0.00      0.00         1\n",
            "         156       0.00      0.00      0.00         2\n",
            "         160       0.00      0.00      0.00         1\n",
            "         161       0.00      0.00      0.00        40\n",
            "         166       0.00      0.00      0.00         1\n",
            "         168       0.00      0.00      0.00        14\n",
            "         170       0.00      0.00      0.00         1\n",
            "         172       0.00      0.00      0.00         1\n",
            "         173       0.00      0.00      0.00         1\n",
            "         175       0.00      0.00      0.00         1\n",
            "         176       0.00      0.00      0.00         1\n",
            "         177       0.00      0.00      0.00       119\n",
            "         178       0.00      0.00      0.00        89\n",
            "         179       0.00      0.00      0.00         1\n",
            "         181       0.00      0.00      0.00         1\n",
            "         183       0.00      0.00      0.00         1\n",
            "         185       0.00      0.00      0.00         1\n",
            "         187       0.00      0.00      0.00         3\n",
            "         188       0.00      0.00      0.00         1\n",
            "         189       0.00      0.00      0.00         1\n",
            "         190       0.00      0.00      0.00       127\n",
            "         191       0.00      0.00      0.00         1\n",
            "         192       0.00      0.00      0.00         1\n",
            "         193       0.00      0.00      0.00         1\n",
            "         194       0.00      0.00      0.00         1\n",
            "         195       0.00      0.00      0.00         1\n",
            "         197       0.00      0.00      0.00         1\n",
            "         198       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.34      5000\n",
            "   macro avg       0.01      0.01      0.01      5000\n",
            "weighted avg       0.27      0.34      0.20      5000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlkD_9nkns2_"
      },
      "source": [
        "it is giving very less accuracy so we should go with other model"
      ]
    }
  ]
}